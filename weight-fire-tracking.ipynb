{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e5dde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "print(\"Using torch\", torch.__version__)\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f94b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each layer has a unique min weight size, std_dev, layer size and transmitter value\n",
    "# to provide a diversity of transmitter values, multiple layers should be used for each layers output\n",
    "class Layer:\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            init_weight_std_dev, \n",
    "            minimum_weight_value, \n",
    "            weight_step_size,\n",
    "            weight_decay_rate,\n",
    "            counter_decay_rate,\n",
    "            input_size, \n",
    "            layer_size, \n",
    "            transmitter_value):\n",
    "                \n",
    "        # store layer configs\n",
    "        self.std_dev = init_weight_std_dev\n",
    "        self.min_weight_value = minimum_weight_value\n",
    "        self.weight_step_size = weight_step_size\n",
    "        self.weight_decay_rate = weight_decay_rate\n",
    "        self.counter_decay_rate = counter_decay_rate\n",
    "        self.input_size = input_size\n",
    "        self.layer_size = layer_size\n",
    "        self.transmitter_value = transmitter_value\n",
    "        \n",
    "        # create initial values for neuron level values\n",
    "        self.activations = torch.ones(layer_size)\n",
    "        self.counters = torch.zeros(layer_size)   \n",
    "        \n",
    "        # create decaying fire tracking tensor\n",
    "        self.fire_trackers = torch.zeros((input_size, layer_size))\n",
    "\n",
    "        # initialize weights with std_dev passed\n",
    "        self.weights = torch.zeros((input_size, layer_size))\n",
    "        nn.init.normal_(self.weights, std=self.std_dev) \n",
    "                \n",
    "    def eval(self, input_tensor, layer_env_reward):\n",
    "        # update weights from last steps reward\n",
    "        #print(\"Updating Weights with reward:\", layer_env_reward)\n",
    "        #print(\"weights:\", self.weights)\n",
    "        #print(\"fire_trackers:\", self.fire_trackers)\n",
    "        self.weights += self.fire_trackers * self.weight_step_size * layer_env_reward\n",
    "        self.fire_trackers *= self.weight_decay_rate\n",
    "        #print(\"new weights:\", self.weights)\n",
    "\n",
    "        #print(\"input:\", input_tensor)\n",
    "        activated_weights = torch.sigmoid(self.weights) \n",
    "        filtered_weight_bool = activated_weights > self.min_weight_value\n",
    "        activated_weights = activated_weights * filtered_weight_bool\n",
    "        #print(\"activated_weights:\", activated_weights)\n",
    "        weightwise_output = (activated_weights.transpose(0,1) * input_tensor).transpose(0,1)\n",
    "        #print(\"weightwise_output:\", weightwise_output)\n",
    "        self.counters += torch.sum(weightwise_output, 0)\n",
    "        #print(\"counters:\", self.counters)\n",
    "        output_bool = self.counters > self.activations\n",
    "        #print(\"output_bool:\", output_bool)\n",
    "        self.fire_trackers += (torch.abs(weightwise_output) * output_bool)\n",
    "        #print(\"fire_trackers:\", self.fire_trackers)\n",
    "        # maybe just set to 0? maybe never can go below 0 either?\n",
    "        self.counters -= self.activations * output_bool\n",
    "        self.counters *= self.counter_decay_rate\n",
    "        #print(\"counters:\", self.counters)\n",
    "        output = output_bool * self.transmitter_value\n",
    "        #print(\"output:\", output)\n",
    "        return output\n",
    "    \n",
    "    def reset(self):\n",
    "        self.fire_trackers = torch.zeros((self.input_size, self.layer_size))\n",
    "        self.counters = torch.zeros(self.layer_size)   \n",
    "        \n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, seed, layers):\n",
    "        torch.manual_seed(seed)\n",
    "        self.layers = layers\n",
    "    \n",
    "    def step(self, input_state):\n",
    "        input_tensor = input_state\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            layer_output = layer.eval(input_tensor)\n",
    "            \n",
    "        output = input_tensor\n",
    "        output_fires = output >= 1\n",
    "        value, action = torch.max(output, axis=0)\n",
    "        action = action.item() \n",
    "        if value == 0:\n",
    "            action = None\n",
    "            \n",
    "        print(\"output\", output, \"action\", action)\n",
    "        return action\n",
    "    \n",
    "    def reset(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ea7f06d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([1, 0]) output: tensor([1, 1]) reward: -1\n",
      "input: tensor([1, 0]) output: tensor([1, 1]) reward: -1\n",
      "input: tensor([1, 0]) output: tensor([1, 1]) reward: -1\n",
      "input: tensor([1, 0]) output: tensor([1, 1]) reward: -1\n",
      "input: tensor([1, 0]) output: tensor([1, 1]) reward: -1\n",
      "accuracy:  -500.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards = []\n",
    "seed = 422 \n",
    "torch.manual_seed(seed)\n",
    "# this will make negative weights, make sure weights are positive (sigmoid?)\n",
    "init_weight_std_dev = .1 \n",
    "minimum_weight_value = .3\n",
    "weight_step_size = .001\n",
    "weight_decay_rate = 0\n",
    "counter_decay_rate = .9\n",
    "\n",
    "pos_symbol_layer = Layer(\n",
    "                    init_weight_std_dev=init_weight_std_dev, \n",
    "                    minimum_weight_value=minimum_weight_value, \n",
    "                    weight_step_size=weight_step_size,\n",
    "                    weight_decay_rate=weight_decay_rate,\n",
    "                    counter_decay_rate=counter_decay_rate,\n",
    "                    input_size=3, \n",
    "                    layer_size=10, \n",
    "                    transmitter_value=1)\n",
    "\n",
    "neg_symbol_layer = Layer(\n",
    "                    init_weight_std_dev=init_weight_std_dev, \n",
    "                    minimum_weight_value=minimum_weight_value, \n",
    "                    weight_step_size=weight_step_size,\n",
    "                    weight_decay_rate=weight_decay_rate,\n",
    "                    counter_decay_rate=counter_decay_rate,\n",
    "                    input_size=3, \n",
    "                    layer_size=10, \n",
    "                    transmitter_value=-1)\n",
    "\n",
    "output_layer = Layer(\n",
    "                init_weight_std_dev=init_weight_std_dev, \n",
    "                minimum_weight_value=minimum_weight_value, \n",
    "                weight_step_size=weight_step_size,\n",
    "                weight_decay_rate=weight_decay_rate,\n",
    "                counter_decay_rate=counter_decay_rate,\n",
    "                input_size=20, \n",
    "                layer_size=2, \n",
    "                transmitter_value=1)\n",
    "\n",
    "iters = 5000\n",
    "\n",
    "# train on xor\n",
    "count = 0\n",
    "for i in range(iters):\n",
    "    pos_symbol_layer.reset()\n",
    "    neg_symbol_layer.reset()\n",
    "    output_layer.reset()\n",
    "    a = np.array([1, 0])\n",
    "    input_tensor = torch.from_numpy(a)\n",
    "    #input_tensor = torch.randint(0, 2, (2,))\n",
    "    # cat a 1 to the end of the input to act as passive control input \n",
    "    effective_input_tensor = torch.cat((input_tensor, torch.ones((1,))))\n",
    "    action = None\n",
    "    output_count = 0\n",
    "    reward = 0\n",
    "    while output_count < 10:\n",
    "        pos_layer_out = pos_symbol_layer.eval(effective_input_tensor, reward)\n",
    "        neg_layer_out = neg_symbol_layer.eval(effective_input_tensor, reward)\n",
    "        \n",
    "        concatted_symbol_outs = torch.cat((pos_layer_out, neg_layer_out))\n",
    "        output = output_layer.eval(concatted_symbol_outs, reward)\n",
    "\n",
    "        value, action = torch.max(output, axis=0)\n",
    "        action = action.item() \n",
    "        if value == 0:\n",
    "            action = None\n",
    "        \n",
    "        output_count += 1\n",
    "        if action == None:\n",
    "            reward = 0\n",
    "        else:\n",
    "            time_steps = 0\n",
    "            \n",
    "            input_sum = torch.sum(input_tensor)\n",
    "            \n",
    "            # output should be false, or index 0\n",
    "            if input_sum == 0 or input_sum == 2:\n",
    "                if output[0] == 1 and output[1] == 0:\n",
    "                    reward = 0\n",
    "                else:\n",
    "                    reward = -1\n",
    "            else:\n",
    "                if output[0] == 0 and output[1] == 1:\n",
    "                    reward = 0\n",
    "                else:\n",
    "                    reward = -1\n",
    "                \n",
    "            if i % 1000 == 0:\n",
    "                print(\"input:\", input_tensor, \"output:\", output, \"reward:\", reward)\n",
    "            \n",
    "            rewards.append(reward)\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"accuracy: \", sum(rewards) / (output_count))\n",
    "plt.cla()\n",
    "plt.plot(rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5dd95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
